{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc99ba0-ad8a-44c8-bb45-e19b359e52bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+-------------------------------+-------------+\n",
      "|MÊS COMPETÊNCIA|MÊS REFERÊNCIA|UF |CÓDIGO MUNICÍPIO SIAFI|NOME MUNICÍPIO|CPF FAVORECIDO|NIS FAVORECIDO|NOME FAVORECIDO                |VALOR PARCELA|\n",
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+-------------------------------+-------------+\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.833.642-**|16167611395   |ABIGAIL DAGMAR MACHADO         |850,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |null          |16122034321   |ABRAAO AMORA SALGUEIRO         |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.355.042-**|16121660806   |ABRAAO DA PIEDADE DO NASCIMENTO|750,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.050.782-**|16094443293   |ABRAO KEMPNER RUMANZKI         |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.455.212-**|16110238660   |ACHILLA MARIA SOUZA ANDRADE    |700,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.305.412-**|20796469754   |ADALCICLEIA BARROS DE ARAUJO   |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.332.032-**|16120063855   |ADALGIZA NOGUEIRA DOS SANTOS   |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.492.902-**|16120063561   |ADAO DE SOUZA PIEDADE          |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |null          |20369134251   |ADAO INES DE MELO              |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.402.382-**|12866781408   |ADECILDO DA SILVA CORREIA      |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.089.602-**|21208225415   |ADEIDE RODRIGUES DAMASCENO     |700,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.469.322-**|16036929952   |ADELINA XUITES JACOB           |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.223.938-**|20060288897   |ADEMIR DANTAS DOS SANTOS JUNIOR|600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.217.922-**|20500011774   |ADENILDA TAVARES DA SILVA      |960,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.092.642-**|12636981006   |ADENILSON MELO DA COSTA        |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.593.192-**|20326549867   |ADENILZA MACHADO PINHEIRO      |800,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |null          |12522975600   |ADENIR BOTELHO HERINGER        |600,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.517.842-**|21205836847   |ADILIA TAMAIA DOS SANTOS       |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.105.572-**|23677502671   |ADILINO DA SILVA BARROSO       |650,00       |\n",
      "|202306         |202306        |AC |643                   |ACRELANDIA    |***.387.772-**|23887628078   |ADILSON DIAS BARBOSA           |600,00       |\n",
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+-------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Iniciar a sessão Spark\n",
    "# Definir um tamanho máximo de memória disponível para uso pelo driver\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bolsa Familia Data Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Atribui o SparkContext à variável 'sc'\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Definir o caminho do arquivo CSV\n",
    "csv_file_path = 'BolsaFamilia/202306_NovoBolsaFamilia.csv'\n",
    "\n",
    "# Ler os dados do CSV para um DataFrame. Aqui, assumimos que o arquivo CSV possui um cabeçalho.\n",
    "# Também inferimos automaticamente o esquema dos dados. Adicionalmente, como o delimitador\n",
    "# padrão de um arquivo CSV é uma vírgula e o arquivo que estamos usando pode ter um delimitador diferente\n",
    "# (como ponto e vírgula), especificamos isso na opção 'sep'. Também indicamos o caractere de aspas\n",
    "# com a opção 'quote'. Para lidar com questões de codificação de caracteres que podem surgir ao trabalhar\n",
    "# com arquivos em formatos diferentes de UTF-8, usamos a opção 'encoding' para definir a codificação\n",
    "# correta, que neste caso é 'ISO-8859-1'.\n",
    "bolsa_familia_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"encoding\", \"ISO-8859-1\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .csv(csv_file_path)\n",
    "\n",
    "# Mostrar as primeiras linhas do DataFrame para verificação. Aqui, usamos 'truncate=False' para garantir\n",
    "# que o Spark exiba o conteúdo completo das células do DataFrame, o que é útil para visualizar dados\n",
    "# com conteúdo mais extenso.\n",
    "bolsa_familia_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98112a43-50ea-43f4-b04d-a0572576f8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Registrar o DataFrame como uma tabela temporária\n",
    "bolsa_familia_df.createOrReplaceTempView(\"bolsa_familia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997117de-0e67-4d9a-b3ff-b32d12d45f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------------+-------------+\n",
      "|NOME MUNICÍPIO|NOME FAVORECIDO                |VALOR PARCELA|\n",
      "+--------------+-------------------------------+-------------+\n",
      "|ACRELANDIA    |ABIGAIL DAGMAR MACHADO         |850,00       |\n",
      "|ACRELANDIA    |ABRAAO AMORA SALGUEIRO         |600,00       |\n",
      "|ACRELANDIA    |ABRAAO DA PIEDADE DO NASCIMENTO|750,00       |\n",
      "|ACRELANDIA    |ABRAO KEMPNER RUMANZKI         |600,00       |\n",
      "|ACRELANDIA    |ACHILLA MARIA SOUZA ANDRADE    |700,00       |\n",
      "|ACRELANDIA    |ADALCICLEIA BARROS DE ARAUJO   |650,00       |\n",
      "|ACRELANDIA    |ADALGIZA NOGUEIRA DOS SANTOS   |600,00       |\n",
      "|ACRELANDIA    |ADAO DE SOUZA PIEDADE          |600,00       |\n",
      "|ACRELANDIA    |ADAO INES DE MELO              |600,00       |\n",
      "|ACRELANDIA    |ADECILDO DA SILVA CORREIA      |650,00       |\n",
      "|ACRELANDIA    |ADEIDE RODRIGUES DAMASCENO     |700,00       |\n",
      "|ACRELANDIA    |ADELINA XUITES JACOB           |650,00       |\n",
      "|ACRELANDIA    |ADEMIR DANTAS DOS SANTOS JUNIOR|600,00       |\n",
      "|ACRELANDIA    |ADENILDA TAVARES DA SILVA      |960,00       |\n",
      "|ACRELANDIA    |ADENILSON MELO DA COSTA        |650,00       |\n",
      "|ACRELANDIA    |ADENILZA MACHADO PINHEIRO      |800,00       |\n",
      "|ACRELANDIA    |ADENIR BOTELHO HERINGER        |600,00       |\n",
      "|ACRELANDIA    |ADILIA TAMAIA DOS SANTOS       |650,00       |\n",
      "|ACRELANDIA    |ADILINO DA SILVA BARROSO       |650,00       |\n",
      "|ACRELANDIA    |ADILSON DIAS BARBOSA           |600,00       |\n",
      "+--------------+-------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consulta simples que seleciona algumas colunas da tabela\n",
    "result_df = spark.sql(\"\"\"\n",
    "SELECT `NOME MUNICÍPIO`, `NOME FAVORECIDO`, `VALOR PARCELA`\n",
    "FROM bolsa_familia\n",
    "\"\"\")\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1521e5-f2e6-4806-8dad-82611593305e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+--------------------+-------------+\n",
      "|MÊS COMPETÊNCIA|MÊS REFERÊNCIA| UF|CÓDIGO MUNICÍPIO SIAFI|NOME MUNICÍPIO|CPF FAVORECIDO|NIS FAVORECIDO|     NOME FAVORECIDO|VALOR PARCELA|\n",
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+--------------------+-------------+\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.833.642-**|   16167611395|ABIGAIL DAGMAR MA...|       850,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|          null|   16122034321|ABRAAO AMORA SALG...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.355.042-**|   16121660806|ABRAAO DA PIEDADE...|       750,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.050.782-**|   16094443293|ABRAO KEMPNER RUM...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.455.212-**|   16110238660|ACHILLA MARIA SOU...|       700,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.305.412-**|   20796469754|ADALCICLEIA BARRO...|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.332.032-**|   16120063855|ADALGIZA NOGUEIRA...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.492.902-**|   16120063561|ADAO DE SOUZA PIE...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|          null|   20369134251|   ADAO INES DE MELO|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.402.382-**|   12866781408|ADECILDO DA SILVA...|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.089.602-**|   21208225415|ADEIDE RODRIGUES ...|       700,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.469.322-**|   16036929952|ADELINA XUITES JACOB|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.223.938-**|   20060288897|ADEMIR DANTAS DOS...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.217.922-**|   20500011774|ADENILDA TAVARES ...|       960,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.092.642-**|   12636981006|ADENILSON MELO DA...|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.593.192-**|   20326549867|ADENILZA MACHADO ...|       800,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|          null|   12522975600|ADENIR BOTELHO HE...|       600,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.517.842-**|   21205836847|ADILIA TAMAIA DOS...|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.105.572-**|   23677502671|ADILINO DA SILVA ...|       650,00|\n",
      "|         202306|        202306| AC|                   643|    ACRELANDIA|***.387.772-**|   23887628078|ADILSON DIAS BARBOSA|       600,00|\n",
      "+---------------+--------------+---+----------------------+--------------+--------------+--------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executar uma consulta SQL e mostrar os resultados diretamente\n",
    "spark.sql(\"SELECT * FROM bolsa_familia\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583fed2e-b02c-4483-825e-beb1d6a7ae4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------+\n",
      "|NOME MUNICÍPIO          |total_valor|\n",
      "+------------------------+-----------+\n",
      "|CRUZEIRO DO SUL         |1.061035E7 |\n",
      "|ESTRELA DE ALAGOAS      |2151199.0  |\n",
      "|BATALHA                 |6848992.0  |\n",
      "|CAMPO ALEGRE            |4174968.0  |\n",
      "|DOIS RIACHOS            |1807040.0  |\n",
      "|LAGOA DA CANOA          |2846837.0  |\n",
      "|GUAJARA                 |2499744.0  |\n",
      "|MONTEIROPOLIS           |1230435.0  |\n",
      "|MAUES                   |1.1029124E7|\n",
      "|IGREJA NOVA             |2637726.0  |\n",
      "|ASSIS BRASIL            |1407480.0  |\n",
      "|SAO MIGUEL DOS CAMPOS   |6794312.0  |\n",
      "|PORTO WALTER            |1576825.0  |\n",
      "|SAO GABRIEL DA CACHOEIRA|6399189.0  |\n",
      "|RIO BRANCO              |2.9420177E7|\n",
      "|FEIRA GRANDE            |3274435.0  |\n",
      "|JUTAI                   |4016887.0  |\n",
      "|OLHO D'AGUA DAS FLORES  |2974808.0  |\n",
      "|MATRIZ DE CAMARAGIBE    |3187671.0  |\n",
      "|INHAPI                  |2698601.0  |\n",
      "+------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Soma das parcelas por município\n",
    "sum_df = spark.sql(\"\"\"\n",
    "SELECT `NOME MUNICÍPIO`, SUM(CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT)) AS total_valor\n",
    "FROM bolsa_familia\n",
    "GROUP BY `NOME MUNICÍPIO`\n",
    "\"\"\")\n",
    "sum_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1dd7f9-e526-49cd-a08d-a32d4890b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soma das parcelas por município com formatação de moeda\n",
    "sum_df = spark.sql(\"\"\"\n",
    "SELECT `NOME MUNICÍPIO`, \n",
    "       format_number(SUM(CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT)), 2) AS total_valor\n",
    "FROM bolsa_familia\n",
    "GROUP BY `NOME MUNICÍPIO`\n",
    "\"\"\")\n",
    "sum_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98848a0c-1b3f-450e-9e34-79dcb547574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média do valor das parcelas\n",
    "avg_df = spark.sql(\"\"\"\n",
    "SELECT AVG(CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT)) AS avg_valor\n",
    "FROM bolsa_familia\n",
    "\"\"\")\n",
    "avg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703f04f-8f77-43be-bc66-7274849e0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregação por município para encontrar o total distribuído e o número de beneficiários\n",
    "aggregated_df = spark.sql(\"\"\"\n",
    "SELECT `NOME MUNICÍPIO`, \n",
    "       COUNT(*) AS numero_beneficiarios,\n",
    "       SUM(CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT)) AS total_distribuido\n",
    "FROM bolsa_familia\n",
    "GROUP BY `NOME MUNICÍPIO`\n",
    "ORDER BY total_distribuido DESC\n",
    "\"\"\")\n",
    "aggregated_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685ed266-0bf0-4b1e-ac1f-ba35dbd3bf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------+\n",
      "|NOME FAVORECIDO                     |VALOR_PARCELA|\n",
      "+------------------------------------+-------------+\n",
      "|ANTONIO MANOEL PEREIRA CONCEICAO    |4106.0       |\n",
      "|CRISTIANE ALMEIDA LARANJEIRA        |4140.0       |\n",
      "|GEAZI PEREIRA PIMENTA               |4390.0       |\n",
      "|IRISLANDIA SOARES ARAUJO            |4198.0       |\n",
      "|JOSE NALDAM SOARES BRITO            |4514.0       |\n",
      "|MARINA SOARES FARIAS                |4006.0       |\n",
      "|MATHEUS LUZ SILVA                   |4322.0       |\n",
      "|PEDRO DOS SANTOS PINHEIRO DE ALMEIDA|4230.0       |\n",
      "|SANDRO AUGUSTO PAVAO PEREIRA        |4040.0       |\n",
      "|VIVIA MERCIA NUNES MOREIRA          |4130.0       |\n",
      "|ROSENDO CAETANO DE SARGES           |4080.0       |\n",
      "+------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionar todos os favorecidos que receberam mais de um valor específico\n",
    "high_value_df = spark.sql(\"\"\"\n",
    "SELECT `NOME FAVORECIDO`, CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT) AS `VALOR_PARCELA`\n",
    "FROM bolsa_familia\n",
    "WHERE CAST(REPLACE(`VALOR PARCELA`, ',', '.') AS FLOAT) > 4000\n",
    "\"\"\")\n",
    "high_value_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc75735-5693-4a0f-8961-2225a9c9c51c",
   "metadata": {},
   "source": [
    "## Exemplo do Uso de Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560ea14-eadb-4c40-8b20-4e4ce0f8bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados e criar um DataFrame\n",
    "df = spark.read.csv(\"path_to_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Registrar o DataFrame como uma tabela temporária\n",
    "df.createOrReplaceTempView(\"my_table\")\n",
    "\n",
    "# Cache a tabela após a primeira operação de transformação\n",
    "spark.sql(\"SELECT * FROM my_table WHERE some_column > some_value\").cache().createOrReplaceTempView(\"filtered_table\")\n",
    "\n",
    "# Executar várias operações de transformação em sequência no DataFrame cacheado\n",
    "# Como o DataFrame está cacheado, estas operações subsequentes serão mais rápidas\n",
    "\n",
    "# Por exemplo, contar os registros\n",
    "spark.sql(\"SELECT COUNT(*) FROM filtered_table\").show()\n",
    "\n",
    "# Calcular a média de uma coluna\n",
    "spark.sql(\"SELECT AVG(numeric_column) FROM filtered_table\").show()\n",
    "\n",
    "# Agrupar por uma coluna e contar os valores\n",
    "spark.sql(\"SELECT category_column, COUNT(*) FROM filtered_table GROUP BY category_column\").show()\n",
    "\n",
    "# Após as operações, é bom liberar o cache para evitar o uso desnecessário de memória\n",
    "spark.catalog.uncacheTable(\"filtered_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738aba6-00df-4597-9966-c1e4862d5b6f",
   "metadata": {},
   "source": [
    "## Interoperabilidade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9019fe1c-de28-4781-b717-2f755f556ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------------------+\n",
      "|id_cliente|       nome| sobrenome|               email|\n",
      "+----------+-----------+----------+--------------------+\n",
      "|         1|     Esther|  Teixeira|mariana858948@exa...|\n",
      "|         2|    Mariane|   Barbosa|isissilva7264@exa...|\n",
      "|         3|Ana Vitória|     Moura|fernandesjoaquim8...|\n",
      "|         4|    Leandro|     Viana|brunosilva8705@ex...|\n",
      "|         5|     Pietro|    Santos|ana-julia375761@e...|\n",
      "|         6|    Clarice|    da Paz|duarteotavio7887@...|\n",
      "|         7|Ana Vitória|  da Cunha|caue115510@exampl...|\n",
      "|         8| Ana Sophia|   da Mota|moraesantonio7820...|\n",
      "|         9|   Leonardo|    Fogaça|teixeiraenrico929...|\n",
      "|        10|    Anthony|   Cardoso|eduardo553737@exa...|\n",
      "|        11|    Natália|    Mendes|maite253689@examp...|\n",
      "|        12|       Davi|      Dias|heloisa037394@exa...|\n",
      "|        13|   Stephany|   Cardoso|jesusesther4336@e...|\n",
      "|        14|      Laura|   da Cruz|maysaalves2332@ex...|\n",
      "|        15| Ana Sophia|    da Luz|aragaoluana6816@e...|\n",
      "|        16|       Levi|  Teixeira|kevin309132@examp...|\n",
      "|        17|      Alice|  da Costa|teixeiralucas7355...|\n",
      "|        18|     Marina|Nascimento|aragaoraquel6201@...|\n",
      "|        19|     Danilo|  Monteiro|zviana4024@exampl...|\n",
      "|        20|     Marina|      Lima|augusto093169@exa...|\n",
      "+----------+-----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ler dados de um arquivo CSV\n",
    "df_csv = spark.read.csv(\"arquivos/clientes.csv\", header=True, inferSchema=True)\n",
    "df_csv.createOrReplaceTempView(\"csv_table\")\n",
    "\n",
    "# Executar uma consulta SQL diretamente sobre os dados CSV\n",
    "spark.sql(\"SELECT id_cliente, nome, sobrenome, email FROM csv_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a533288-70ab-4ede-8187-3302e04ce431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cliente: struct (nullable = true)\n",
      " |    |-- celular: string (nullable = true)\n",
      " |    |-- cpf: string (nullable = true)\n",
      " |    |-- data_atualizacao: string (nullable = true)\n",
      " |    |-- data_criacao: string (nullable = true)\n",
      " |    |-- data_nascimento: string (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- endereco: struct (nullable = true)\n",
      " |    |    |-- bairro: string (nullable = true)\n",
      " |    |    |-- cep: string (nullable = true)\n",
      " |    |    |-- cidade: string (nullable = true)\n",
      " |    |    |-- estado: string (nullable = true)\n",
      " |    |    |-- numero: string (nullable = true)\n",
      " |    |    |-- pais: string (nullable = true)\n",
      " |    |    |-- rua: string (nullable = true)\n",
      " |    |-- genero: string (nullable = true)\n",
      " |    |-- id_cliente: long (nullable = true)\n",
      " |    |-- nome: string (nullable = true)\n",
      " |    |-- sobrenome: string (nullable = true)\n",
      " |    |-- status: boolean (nullable = true)\n",
      " |    |-- telefone: string (nullable = true)\n",
      "\n",
      "+-----------+-------------+------+\n",
      "|nome       |rua          |cidade|\n",
      "+-----------+-------------+------+\n",
      "|Esther     |Vila da Costa|Alves |\n",
      "|Mariane    |Vila da Costa|Alves |\n",
      "|Ana Vitória|Vila da Costa|Alves |\n",
      "+-----------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Criar uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"JsonRead\").getOrCreate()\n",
    "\n",
    "# Ler o arquivo JSON original com a opção \"multiline\"\n",
    "df_json = spark.read.option(\"multiline\", \"true\").json(\"arquivos/clientes.json\")\n",
    "\n",
    "# Aplanar o array de clientes usando explode e acessar os objetos cliente\n",
    "df_exploded = df_json.select(explode(df_json.clientes).alias(\"cliente\"))\n",
    "\n",
    "# Mostrar o esquema e os dados aplanados\n",
    "df_exploded.printSchema()\n",
    "# Assumindo que 'df_exploded' é o seu DataFrame que contém a coluna 'cliente' aplanada\n",
    "\n",
    "# Criar uma visualização temporária\n",
    "df_exploded.createOrReplaceTempView(\"clientes_view\")\n",
    "\n",
    "# Agora você pode executar consultas SQL usando a visualização temporária 'clientes_view'\n",
    "# Por exemplo, para selecionar todos os clientes:\n",
    "spark.sql(\"SELECT cliente.nome, cliente.endereco.rua, cliente.endereco.cidade FROM clientes_view\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d16b468-429d-4f73-b2b0-64067c93da24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_exploded.write.format(\"parquet\").saveAsTable(\"clientes_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76300768-9d94-4480-a3ff-c689fe7eb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SaveAsTableExample\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/caminho/para/o/diretorio/desejado\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e37b9-2c23-484d-9654-bb586dc4e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração\n",
    "df_exploded.write.format(\"parquet\").save(\"/caminho/para/o/diretorio/desejado/clientes_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3942bdc-9daa-42d0-9499-09d3f6b8e55d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+\n",
      "|       nome|sobrenome|          rua|\n",
      "+-----------+---------+-------------+\n",
      "|     Esther| Teixeira|Vila da Costa|\n",
      "|    Mariane|  Barbosa|Vila da Costa|\n",
      "|Ana Vitória|    Moura|Vila da Costa|\n",
      "+-----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ler dados de um arquivo Parquet\n",
    "df_parquet = spark.read.parquet(\"spark-warehouse/clientes_table/part-00000-8809baa0-abd3-48b2-a95a-7dab6fdc6078-c000.snappy.parquet\")\n",
    "df_parquet.createOrReplaceTempView(\"parquet_table\")\n",
    "\n",
    "# Executar uma consulta SQL diretamente sobre os dados Parquet\n",
    "spark.sql(\"SELECT cliente.nome, cliente.sobrenome, cliente.endereco.rua FROM parquet_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8f45ac-da1d-4627-9bd7-bfe8c73770e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/postgresql-42.2.5.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11be5f16-2f62-4387-9cd8-7f1520abc253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+----------+---------------+--------------------+---------------+---------------+-----------+------+--------------------+--------------------+------+\n",
      "|id_cliente|       nome|id_endereco| sobrenome|data_nascimento|               email|       telefone|        celular|        cpf|genero|        data_criacao|    data_atualizacao|status|\n",
      "+----------+-----------+-----------+----------+---------------+--------------------+---------------+---------------+-----------+------+--------------------+--------------------+------+\n",
      "|         1|     Esther|        163|  Teixeira|     2000-09-29|mariana858948@exa...|(65) 79034-9652|(22) 90597-2207|71284960331|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         2|    Mariane|        152|   Barbosa|     2005-01-01|isissilva7264@exa...|(29) 25866-7664|(42) 62029-1129|38607941240|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         3|Ana Vitória|         41|     Moura|     1972-05-02|fernandesjoaquim8...|(51) 45846-4436|(79) 89364-2613|87019632440|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         4|    Leandro|         54|     Viana|     1957-10-05|brunosilva8705@ex...|(52) 13001-4571|(61) 28192-2969|98634712591|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         5|     Pietro|         56|    Santos|     1948-11-03|ana-julia375761@e...|(67) 19581-9257|(71) 13107-6381|82460719396|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         6|    Clarice|        113|    da Paz|     1991-11-08|duarteotavio7887@...|(80) 38565-8710|(21) 42752-4579|80639472583|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         7|Ana Vitória|         56|  da Cunha|     1998-10-06|caue115510@exampl...|(51) 34456-6880|(96) 28108-6057|75489310693|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         8| Ana Sophia|         53|   da Mota|     1965-12-18|moraesantonio7820...|(90) 86986-2870|(60) 19230-5176|62314759800|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|         9|   Leonardo|        151|    Fogaça|     1983-10-21|teixeiraenrico929...|(85) 33246-2731|(19) 61606-3575|70893145610|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        10|    Anthony|        116|   Cardoso|     1946-03-09|eduardo553737@exa...|(80) 58794-2587|(41) 41500-9144|03615842707|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        11|    Natália|        131|    Mendes|     1945-12-15|maite253689@examp...|(68) 64468-8196|(38) 16566-2909|35920678186|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        12|       Davi|        179|      Dias|     1983-01-22|heloisa037394@exa...|(71) 49996-5156|(53) 91734-9403|01672435943|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        13|   Stephany|        123|   Cardoso|     1958-10-02|jesusesther4336@e...|(40) 96986-1005|(78) 75134-4146|63798402574|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        14|      Laura|        118|   da Cruz|     1957-07-26|maysaalves2332@ex...|(46) 68716-4102|(67) 88537-4949|23480765190|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        15| Ana Sophia|        156|    da Luz|     1974-07-05|aragaoluana6816@e...|(14) 92416-1668|(13) 73620-2140|35084619206|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        16|       Levi|         38|  Teixeira|     1966-04-06|kevin309132@examp...|(92) 49813-1349|(98) 46928-5316|24073619896|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        17|      Alice|        104|  da Costa|     1982-05-27|teixeiralucas7355...|(93) 69925-5720|(92) 64089-7342|67014389548|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        18|     Marina|        152|Nascimento|     1997-06-23|aragaoraquel6201@...|(70) 51097-7401|(48) 26131-1471|51320647871|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        19|     Danilo|         72|  Monteiro|     1987-04-02|zviana4024@exampl...|(60) 60032-3404|(18) 69441-7413|80536241970|     F|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "|        20|     Marina|         46|      Lima|     1950-05-10|augusto093169@exa...|(13) 74635-9266|(75) 27979-5037|25439870610|     M|2023-10-22 01:59:...|2023-10-22 01:59:...|  true|\n",
      "+----------+-----------+-----------+----------+---------------+--------------------+---------------+---------------+-----------+------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conectar ao banco de dados PostgreSQL via JDBC\n",
    "df_postgres = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:5432/01_pdv\") \\\n",
    "    .option(\"dbtable\", \"public.clientes\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "df_postgres.createOrReplaceTempView(\"clientes\")\n",
    "\n",
    "# Executar uma consulta SQL diretamente sobre os dados do PostgreSQL\n",
    "spark.sql(\"SELECT * FROM clientes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58720683-75a7-4605-acb1-3280d228a786",
   "metadata": {},
   "source": [
    "## UDF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d10b4bd-7217-4666-a2e3-68f04030cece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|id_cliente|       nome|idade|\n",
      "+----------+-----------+-----+\n",
      "|         1|     Esther|   23|\n",
      "|         2|    Mariane|   18|\n",
      "|         3|Ana Vitória|   51|\n",
      "|         4|    Leandro|   66|\n",
      "|         5|     Pietro|   75|\n",
      "|         6|    Clarice|   32|\n",
      "|         7|Ana Vitória|   25|\n",
      "|         8| Ana Sophia|   58|\n",
      "|         9|   Leonardo|   40|\n",
      "|        10|    Anthony|   77|\n",
      "|        11|    Natália|   78|\n",
      "|        12|       Davi|   40|\n",
      "|        13|   Stephany|   65|\n",
      "|        14|      Laura|   66|\n",
      "|        15| Ana Sophia|   49|\n",
      "|        16|       Levi|   57|\n",
      "|        17|      Alice|   41|\n",
      "|        18|     Marina|   26|\n",
      "|        19|     Danilo|   36|\n",
      "|        20|     Marina|   73|\n",
      "+----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Inicializando uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"UDFExample\").getOrCreate()\n",
    "\n",
    "# Definindo uma função Python para calcular a idade\n",
    "def calculate_age(birthdate):\n",
    "    if isinstance(birthdate, datetime):\n",
    "        birthdate = birthdate.date()\n",
    "    elif isinstance(birthdate, str):\n",
    "        birthdate = datetime.strptime(birthdate, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    today = date.today()\n",
    "    return today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "\n",
    "# Registrando a função como UDF\n",
    "calculate_age_udf = udf(calculate_age, IntegerType())\n",
    "\n",
    "# Lendo o arquivo CSV\n",
    "df = spark.read.csv('arquivos/clientes.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Convertendo a coluna 'data_nascimento' para tipo data\n",
    "df = df.withColumn(\"data_nascimento\", to_date(col(\"data_nascimento\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Adicionando a coluna 'idade' usando a UDF\n",
    "df = df.withColumn(\"idade\", calculate_age_udf(col(\"data_nascimento\")))\n",
    "\n",
    "# Selecionando colunas específicas\n",
    "df.select(\"id_cliente\", \"nome\", \"idade\").show()\n",
    "\n",
    "# Salvando o DataFrame modificado\n",
    "df.write.format(\"parquet\").mode(\"ignore\").save(\"arquivos/parquet/clientes_por_idade.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "054b6bd2-84b6-4e1e-9866-636955cb9ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|id_cliente|       nome|idade|\n",
      "+----------+-----------+-----+\n",
      "|         1|     Esther|   23|\n",
      "|         2|    Mariane|   18|\n",
      "|         3|Ana Vitória|   51|\n",
      "|         4|    Leandro|   66|\n",
      "|         5|     Pietro|   75|\n",
      "|         6|    Clarice|   32|\n",
      "|         7|Ana Vitória|   25|\n",
      "|         8| Ana Sophia|   58|\n",
      "|         9|   Leonardo|   40|\n",
      "|        10|    Anthony|   77|\n",
      "|        11|    Natália|   78|\n",
      "|        12|       Davi|   40|\n",
      "|        13|   Stephany|   65|\n",
      "|        14|      Laura|   66|\n",
      "|        15| Ana Sophia|   49|\n",
      "|        16|       Levi|   57|\n",
      "|        17|      Alice|   41|\n",
      "|        18|     Marina|   26|\n",
      "|        19|     Danilo|   36|\n",
      "|        20|     Marina|   73|\n",
      "+----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Inicializando uma SparkSession\n",
    "spark = SparkSession.builder.appName(\"UDFExample\").getOrCreate()\n",
    "\n",
    "# Definindo uma função Python para calcular a idade\n",
    "def calculate_age(birthdate):\n",
    "    if isinstance(birthdate, datetime):\n",
    "        birthdate = birthdate.date()\n",
    "    elif isinstance(birthdate, str):\n",
    "        birthdate = datetime.strptime(birthdate, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    today = date.today()\n",
    "    return today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "\n",
    "# Registrando a função como UDF no contexto SQL\n",
    "spark.udf.register(\"calculate_age\", calculate_age, IntegerType())\n",
    "\n",
    "# Lendo o arquivo CSV\n",
    "df = spark.read.csv('arquivos/clientes.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Convertendo a coluna 'data_nascimento' para tipo data\n",
    "df = df.withColumn(\"data_nascimento\", to_date(col(\"data_nascimento\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Criando uma view temporária para usar SQL\n",
    "df.createOrReplaceTempView(\"clientes\")\n",
    "\n",
    "# Usando a UDF em uma consulta SQL\n",
    "spark.sql(\"SELECT id_cliente, nome, calculate_age(data_nascimento) AS idade FROM clientes\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a00f2-e51e-4ad7-bc1e-d24ea73cd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Conversão de Temperatura\n",
    "### Uma UDF para converter temperaturas de Celsius para Fahrenheit e vice-versa pode ser \n",
    "### bastante útil em análises envolvendo dados climáticos ou ambientais.\n",
    "\n",
    "def celsius_to_fahrenheit(celsius):\n",
    "    return (celsius * 9/5) + 32\n",
    "\n",
    "def fahrenheit_to_celsius(fahrenheit):\n",
    "    return (fahrenheit - 32) * 5/9\n",
    "\n",
    "spark.udf.register(\"celsius_to_fahrenheit\", celsius_to_fahrenheit, DoubleType())\n",
    "spark.udf.register(\"fahrenheit_to_celsius\", fahrenheit_to_celsius, DoubleType())\n",
    "\n",
    "### 2. Tratamento de Strings\n",
    "### UDFs para tratamento de strings, como a remoção de espaços em branco, \n",
    "### conversão para maiúsculas ou minúsculas, podem ser úteis em várias situações, especialmente na limpeza de dados.\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return text.strip()\n",
    "\n",
    "def to_uppercase(text):\n",
    "    return text.upper()\n",
    "\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "spark.udf.register(\"remove_whitespace\", remove_whitespace, StringType())\n",
    "spark.udf.register(\"to_uppercase\", to_uppercase, StringType())\n",
    "spark.udf.register(\"to_lowercase\", to_lowercase, StringType())\n",
    "\n",
    "### 3. Cálculo de Distância\n",
    "### Para conjuntos de dados geográficos, uma UDF para calcular a distância entre dois pontos \n",
    "### (latitude e longitude) pode ser muito útil.\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convertendo coordenadas de graus para radianos\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Fórmula de Haversine\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Raio da Terra em quilômetros\n",
    "    return c * r\n",
    "\n",
    "spark.udf.register(\"haversine\", haversine, DoubleType())\n",
    "\n",
    "### 4. Tratamento de Datas\n",
    "### UDFs para manipulação de datas, como calcular a diferença entre datas ou adicionar/subtrair \n",
    "### dias a uma data, são extremamente úteis em muitos contextos.\n",
    "\n",
    "def days_between(date1, date2):\n",
    "    return (date2 - date1).days\n",
    "\n",
    "def add_days(date, days):\n",
    "    return date + timedelta(days=days)\n",
    "\n",
    "spark.udf.register(\"days_between\", days_between, IntegerType())\n",
    "spark.udf.register(\"add_days\", add_days, DateType())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
